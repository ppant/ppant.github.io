---
id: 1929
title: Books recommendation series
date: 2019-03-16T16:12:59+05:30
author: Pradeep Pant
layout: revision
guid: http://pradeeppant.com/2019/03/1918-revision-v1/
permalink: /2019/03/16/1918-revision-v1/
---
Since long I was thinking to write down my recommendation of the books I have read recently or in <g class="gr_ gr\_38 gr-alert gr\_gramm gr\_inline\_cards gr\_run\_anim Grammar only-ins replaceWithoutSep" id="38" data-gr-id="38">past</g> as well. The plan is to post <g class="gr_ gr\_5 gr-alert gr\_spell gr\_inline\_cards gr\_run\_anim ContextualSpelling ins-del multiReplace" id="5" data-gr-id="5"><g class="gr_ gr\_17 gr-alert gr\_spell gr\_inline\_cards gr\_disable\_anim_appear ContextualSpelling ins-del multiReplace" id="17" data-gr-id="17">atleast</g></g> one book recommendation weekly.  


Check below my first recommendation. 

## Book 

Elements of statistical learning  
Hastie, Tibshirani, and Friedman (2009 )  
 <https://web.stanford.edu/~hastie/ElemStatLearn/>  


## Theme

During the past decade has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. The book&#8217;s coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting&#8211;the first comprehensive treatment of this topic in any book.&nbsp; 

## Takeaway

It is a rigorous and mathematically dense book on machine learning techniques. It focuses mainly on supervised learning techniques. It gives a very good explanation of how the correlation between Bias, Variance and Model Complexity works. If you have the mathematical background (calculus, linear algebra etc) this is a very good introduction to Machine Learning and covers most of the MI topics.  
I can say that it has a nice balance between mathematical concepts and intuitive reasoning.  
I highly recommend this book for anyone entering <g class="gr_ gr\_534 gr-alert gr\_gramm gr\_inline\_cards gr\_run\_anim Grammar replaceWithoutSep" id="534" data-gr-id="534">to</g> the field of AI/ML. 

## Suggestions

  * What this book doesn&#8217;t provide? is a pragmatic approach or Hands-on practice.
  * Deep analysis of why a specific method works (but it gives you some intuition about what a method is trying to do)
  * If you are doing self-study and don&#8217;t have any background in machine learning or statistics advice to refine your understanding of linear algebra and calculus before reading this book. 
  * Free PDF is available but suggest to buy a print book. 

## Download and purchase link

<p class="has-text-color has-background has-small-font-size has-vivid-cyan-blue-color has-very-light-gray-background-color">
  <g class="gr_ gr_25 gr-alert gr_spell gr_inline_cards gr_run_anim ContextualSpelling ins-del" id="25" data-gr-id="25"><strong>Buy</strong></g><strong>: </strong><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a><br /><strong>PDF: </strong>h<a href="https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf">ttps://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf</a>
</p>